{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Kenya Clinical Challenge\n",
                "This notebook orchestrates the entire workflow for the Kenya Clinical Challenge project, including data loading, exploration, cleaning, preprocessing, feature engineering, model training, evaluation, and submission."
            ]
        },
        {
            "cell_type": "code",
            "metadata": {},
            "source": [
                "# Import necessary libraries\n",
                "import pandas as pd\n",
                "from src.data_loading import load_data\n",
                "from src.data_exploration import explore_data\n",
                "from src.data_cleaning import clean_data\n",
                "from src.preprocessing import preprocess_text\n",
                "from src.feature_engineering import generate_embeddings\n",
                "from src.data_splitting import split_data\n",
                "from src.model_training import train_model\n",
                "from src.model_evaluation import evaluate_model\n",
                "from src.submission import prepare_submission\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 1: Load Data\n",
                "Load the training and test datasets."
            ]
        },
        {
            "cell_type": "code",
            "metadata": {},
            "source": [
                "df_train, df_test = load_data('./data/train.csv', './data/test.csv')\n",
                "df_train.head()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 2: Explore Data\n",
                "Analyze the loaded datasets."
            ]
        },
        {
            "cell_type": "code",
            "metadata": {},
            "source": [
                "explore_data(df_train, df_test)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 3: Clean Data\n",
                "Clean the datasets by handling missing values and ensuring consistency."
            ]
        },
        {
            "cell_type": "code",
            "metadata": {},
            "source": [
                "df_train_cleaned, df_test_cleaned = clean_data(df_train, df_test)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 4: Preprocess Text\n",
                "Preprocess the text data in both the training and testing datasets."
            ]
        },
        {
            "cell_type": "code",
            "metadata": {},
            "source": [
                "df_train_cleaned['Prompt'] = preprocess_text(df_train_cleaned['Prompt'])\n",
                "df_test_cleaned['Prompt'] = preprocess_text(df_test_cleaned['Prompt'])"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 5: Feature Engineering\n",
                "Generate text embeddings for the clinical prompts."
            ]
        },
        {
            "cell_type": "code",
            "metadata": {},
            "source": [
                "df_train_cleaned['Prompt_embeddings'] = generate_embeddings(df_train_cleaned['Prompt'])\n",
                "df_test_cleaned['Prompt_embeddings'] = generate_embeddings(df_test_cleaned['Prompt'])"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 6: Split Data\n",
                "Split the training data into training and validation sets."
            ]
        },
        {
            "cell_type": "code",
            "metadata": {},
            "source": [
                "train_data, val_data = split_data(df_train_cleaned)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 7: Train Model\n",
                "Train the model using the prepared datasets."
            ]
        },
        {
            "cell_type": "code",
            "metadata": {},
            "source": [
                "model = train_model(train_data)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 8: Evaluate Model\n",
                "Evaluate the trained model on validation data."
            ]
        },
        {
            "cell_type": "code",
            "metadata": {},
            "source": [
                "evaluation_results = evaluate_model(model, val_data)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 9: Prepare Submission\n",
                "Generate predictions for the test dataset and prepare the submission file."
            ]
        },
        {
            "cell_type": "code",
            "metadata": {},
            "source": [
                "submission_df = prepare_submission(model, df_test_cleaned)\n",
                "submission_df.to_csv('submission.csv', index=False)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}